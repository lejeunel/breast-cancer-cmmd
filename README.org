#+title: A Deep-Learning Approach to Breast Cancer Screening from Mammography Images

* Usage & Configuration

** Using Docker and Make

We provide a ~Dockerfile~ along with a ~Makefile~ to facilitate reproducibility and
abstract-away some pipeline steps.

Prior to run targets, you may setup environment variables:
- ~HMTEST_RUN_DIR~: Where model weights and intermediate validation data will be stored.
- ~HMTEST_DATA_DIR~: Where raw-data and meta-data are stored.

If not set, these directories will be automatically created in project's root.

Finally, you may run the data fetching pipeline with

#+begin_src sh
make ml-splitted-dataset
#+end_src

** On Host Machine

- Install [[https://python-poetry.org/docs/#installation][Poetry]] in user-space.
- move to project's root and install project with:

#+begin_src shell
poetry install
#+end_src

This will look for an existing and activated virtual environment, and create one
in current directory if it does not exist.

Last, check out the pipeline given in the ~Makefile~. Each target basically reduce to
calling a CLI. You may start with:

#+begin_src shell
python hmtest/main.py --help
#+end_src


- TODO: Set permission of files generated from docker container. They are now ~root:root~
** Questions / Next steps
- /The result of the experiments shall be reusable and sharable metrics/: Is this a typo? Does this simply means to generate a predictions on the test set and distribute these as a csv file?
- /We might not need or be able to download the whole dataset so your code should be allow to process a portion of it./
- Investigate on effect of adding classification task on type of abnormality.
