#+title: A Deep-Learning Approach to Breast Cancer Screening from Mammography Images

* Usage
** Using a virtual environment

- Install [[https://python-poetry.org/docs/#installation][Poetry]] in user-space.
- move to project's root and install project with:

#+begin_src shell
poetry install
#+end_src

This will look for an existing and activated virtual environment, and create one
in current directory if it does not exist.

We make available a serie of CLI endpoints to execute the different phases of
our pipeline. The root endpoint is documented at:

#+begin_src shell
python breastclf/main.py --help
#+end_src

*** Pipeline Steps

**** Selecting Series and Merging Annotations

We provide a base meta-data file that contains references to the original CMMD dataset at
~assets/meta.csv~.
Remove rows from this file prior to running the next commands to discard
patients.

First, we merge our base meta-data file with annotations with:

#+begin_src shell
python breastclf/main.py cmmd merge-meta-and-annotations assets/meta.csv assets/annotations.csv <data-dir>/meta-annotated.csv
#+end_src

**** Downloading Raw-data

The raw DICOM files are publicly available on ~cancerimagingarchive.net~.
We provide a routine to download these. We recommend setting ~n-threads~
to >16 to accelerate download time.

#+begin_src shell
python breastclf/main.py cmmd fetch-raw-data -w <n-threads> <data-dir>/meta-annotated.csv <data-dir>/dicom
#+end_src

**** Parse DICOM series
Next, we parse each dicom file to obtain some relevant meta-data:

#+begin_src shell
python breastclf/main.py cmmd build-per-image-meta <data-dir>/meta-annotated.csv <data-dir>/meta-images.csv
#+end_src

**** Convert images

We convert each image to 8-bit in PNG format:

#+begin_src shell
python breastclf/main.py cmmd dicom-to-png <data-dir>/meta-images.csv <data-dir>/dicom <data-dir>/png
#+end_src

**** Making train/val/test Splits
Last, we construct training, validation, and testing splits with:

#+begin_src shell
python breastclf/main.py ml split <data-dir>/meta-images.csv <data-dir>/meta-images-split.csv 0.2 0.2
#+end_src

*** Training

All our models can be trained using commands of the following form:

#+begin_src shell
python breastclf/main.py ml train --cuda --fusion <fusion-mode> --lfabnorm <lfa> --lftype <lft> <data-dir>/meta-images-split.csv <data-dir>/png <run-dir> <experiment-name>
#+end_src

Where:
- ~<fusion-mode>~ sets the fusion strategy.
- ~<lfabnorm>~ is the loss factor applied to the multi-label abnormality classification objective.
- ~<lftype>~ is the loss factor applied to the tumor type classification objective.
- ~<run-dir>~ is the root path where checkpoints, logs, and validation data will be stored.
- ~<experiment-name>~ sets the name of the directory created in ~<run-dir>~.


** Using the docker engine

We make available a Docker image on DockerHub, along with
a ~Makefile~ to facilitate reproducibility and
abstract-away the granular pipeline steps described above.

Prior to run targets, you may customize the following environment variables.
- ~BREASTCLF_RUN_DIR~: Path where checkpoints and results are stored.
- ~BREASTCLF_DATA_DIR~: Path where raw-data, preprocessed images, and meta-data are stored.
- ~BREASTCLF_USE_CUDA~: Flag to use nvidia GPU acceleration (recommended).
  You must first install the [[https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html][Nvidia Container Toolkit]] to use this feature.

  To prepare the dataset prior to training model, run:

 #+begin_src shell
make ml-splitted-dataset
 #+end_src


* Notes

https://stackoverflow.com/questions/25185405/using-gpu-from-a-docker-container

** Baselines:
- /A Comparison of Techniques for Class Imbalance in Deep Learning Classification of Breast Cancer/
- /Deep Learning in Breast Cancer Imaging: A Decade of Progress and Future Directions/
- /Attention-Based Deep Learning System for Classification of Breast Lesionsâ€”Multimodal, Weakly Supervised Approach/

** TODO
- TODO: Set permission of files generated from docker container. They are now ~root:root~
- Implement/document testing phase output:
  - ~test-results.csv~: columns with raw breast-wise predictions of type *and abnormality*
  - ~test-agg-results.csv~: Pre-defined performance metrics (AUC, MMC, F1, ...)
