#+title: A Multi-View Deep-Learning Approach to Breast Cancer Screening from Mammography Images
#+setupfile: setupfile.org
#+OPTIONS: toc:t
#+AUTHOR: Laurent Lejeune
#+EMAIL: me@lejeunel.org
#+cite_export: biblatex
#+bibliography: myrefs.bib
#+LATEX_HEADER: \bibliography{myrefs.bib}

#+BEGIN_SRC python :session :exports none
from pathlib import Path
import seaborn as sns
import pandas as pd
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
matplotlib.use("tkagg")
sns.set_theme(style="darkgrid")

data_path = Path('../data')

#+END_SRC
#+RESULTS:

* Introduction
- [cite:@crawshaw20]: Multi-Task Learning with Deep Neural Networks: A Survey
- [cite:@dai15]: Instance-aware Semantic Segmentation via Multi-task Network Cascades
- [cite:@xu18]: PAD-Net: Multi-Tasks Guided Prediction-and-Distillation Network for
  Simultaneous Depth Estimation and Scene Parsing

* The Chinese Mammography Database (CMMD)

** <<screening>>Screening

We use the publicly available Chinese Mammography Database (CMMD) [cite:@cai23],
which originally contains $\approx 1871$ patients screened for breast cancer.
and filter-out  scans that match the following criteria:

- Patients with history of previous breast biopsy within 1 week, or any therapy for breast lesions
  prior to mammography.
- Patients with breasts prosthesis.
- Images with substantial motion artifact.

This reduces our dataset to $1775$ patients.

** Annotations

Each *study* is analyzed by domain experts so as to assign the following
target variables:

- $y_{t} \in \{\text{benign}, \text{malignant}\, \text{none}\}$ indicates the type of tumor.
- $y_{a} \in \{\text{calcification}, \text{mass}, \text{both}\}$ indicates the type of abnormality, where ~both~ means that both ~calcification~ and ~mass~ are present.
- $y_s \in \{\text{luminal-A}, \text{luminal-B},\text{HER2-positive},\text{triple-negative},\text{missing}\}$ a
  subtype information (possibly missing).

** <<limitations>>Limitations

The CMMD dataset is challenging to use in a Machine Learning setting.
Indeed, for a ML practitioner, coherent labels are crucial to fully exploit
modern techniques. In particular, we found that this dataset includes
the following sources of noise:

1. Each study contains 2 views per breast. This is due to the fact that the visual cues
    that are relevant to distinguish a benign from a malignant tumor are
     sometimes absent from one of the two available views, thereby justifying redundancy.
     In other words, the labels that directly to visible abnormalities, i.e. $y_{a}$,
     have been associated with two views (images), while one of the two could contain no
     abnormalities.

2. While the abnormality labels $y_{a}$ seem to refer to well-defined visible objects,
   we find that these come in at least 2 forms: compact blobs, and clusters.
   Importantly, the latter distinction of form is a crucial clue
   to identify malignancy [cite:@azam21].
   Again, this adds another component of noise in our label set.

3. In our best understanding, $y_{t}$, the malignant/benign label, has been
   assigned following a thorough histopathological protocol, and not solely on the
   basis of the imaging protocol.

While there exists many techniques to deal with noisy labels [cite:@song22],
we choose to investigate on simple arithmetic operations as part of the
training phase.

** Exploration

#+BEGIN_SRC python :session :exports results :results none
from hmtest.ml.dataloader import DataLoader
image_size = 320

dset = DataLoader(data_path / 'png', data_path / 'meta-images-split.csv',
                  split='train')
meta = dset.meta
#+END_SRC


#+BEGIN_SRC python :session :exports none :results none
fig_path = 'images/distrib.png'
fig, ax = plt.subplots(nrows=1, ncols=1)
sns.histplot(meta, x='abnormality', hue="classification", ax=ax)
fig.savefig(fig_path)
#+END_SRC

#+CAPTION: Distributions of abnormalities for diagnosis
#+LABEL: fig:distributions
[[./images/distrib.png]]

#+CAPTION: Example images. On each row, we show two views of the same breast.
#+LABEL: fig:preview
#+ATTR_LATEX: :width 9cm
[[./images/previews.png]]

** <<split>>Curation and Splitting

As we endeavour to use the CMMD dataset to produce an ML solution, we
perform a curation step and split all images in a train, validation, and testing split.

In addition to the filtering criteria described in Sec. [[screening]], we further
discard images that have identical hashes following the authors's recommendations [fn:reco].

In our best understanding, there does not exists an official and publicly avaible train/val/test
split. We therefore make our own through the following steps:

1. We discard all images that have no labels $y_t$ and $y_a$.
2. We group all images by breast, i.e. each group contain two views of the same breast.
3. To perform cross-validation, we divide all groups using a stratified
    shuffled splitting strategy, where each split
    must contain the same proportion of $y_t$ and $y_a$. Our splits contain $60$, $20$,
     and $20\%$ of images for the train, validation, and testing set, respectively.

[fn:reco] https://www.cancerimagingarchive.net/collection/cmmd/

* Methods

We aim to learn a predictor that determines whether a given mammography study
contains a malignant or benign tumor.

At its core, our model extracts features using a Convolutional Neural Network,
and follows with two parallel classification heads.

We now develop our composite objectives and multi-view classification approaches.

** <<multiview>>Learning with Multiple Views

Following previous works in breast cancer screening [cite:@geras17] [cite:@seeland21],
we implement and test several strategies (*fusion mode*) to handle the fact that
labels are assigned to studies (and not images).

1. *Output average*: We assign to all images of the same study
    the mean probability output.
2. *Feature average*: We first compute the mean feature vector of all images of the same
   study. We then pass this vector into the classification layer prior to compute the loss and
   applying back-propagation.
3. *Feature  max*: Similar to previous approach, but we compute the max descriptors instead.

** Auxiliary Task

In addition to our main task of classifying tumors as malignant/benign, we
further investigate on the relevance of adding the auxiliary task of identifying
abnormalities.

In particular, we add a second classifier head to our backbone, and train the whole
model end-to-end to studies in malignant/benign, and calcification/mass/both,
both objectives being optimized in parallel.

We implement similar aggregation strategies given in Sec. [[multiview]].

Note that as shown in Fig. [[fig:distributions]], this auxiliary task belongs to the
/multi-label/ scenario, since a given study/image can potentially
show more than one class.

** Architecture

Our model is a Convolution Neural Network based on the ResNet34
architecture [cite:@he15], where the bottleneck gives $512$ features.
Next, features are mapped to probabilities using linear layers.

We give an illustration of our model in Fig. [[fig:model]].

#+CAPTION: Our model takes as input a set of images that show several views of the same breast. We investigate on several fusion strategies (dashed columns): (1) Fuse features at bottleneck, and (2) fuse prediction outputs. We also set an auxiliary multi-label classification objective on abnormalities (bottom branch).
#+LABEL: fig:model
[[./images/model.png]]

** Preprocessing, Training, and Validation

We convert the original images given as DICOM series into 8-bit images,
and rescale these from $1914 \times 2294$ to $1024 \times 1024$ pixels. We found that this
is a good compromise as it conserves most fine-grained details while
reducing computational burden.

Next, we apply the triangle thresholding approach described in [cite:@walsh22]
to remove background noise.

Finally, we apply vertical mirroring to right breasts so as to align them with left breasts.

We feed our model with mini-batches that combine both views of a given breast, and
apply our fusion operators prior to computing the gradients.

Our classification tasks are optimized as follows:

1. *Type*: Classifies breasts as Malignant/Benign using a Binary Cross-Entropy.
2. *Abnormality*: Classifies breasts as Mass *and/or* calcification using a Binary Cross-Entropy
   in a multi-label fashion, i.e. we apply the sigmoid operator to the outputs.

We train both our backbone and classification heads in an end-to-end regime through
gradient descent using a cross-validation strategy.
We leverage the training/validation splits described in Sec. [[split]], and train for
of $20$ epochs, where each epoch contains $30$ randomly sampled mini-batches,
where each mini-batch contains $16$ images, i.e. $8$ breasts.

Our gradients are computed using the Adam optimizer with a learning rate of
$5 \times 10^{-5}$.

When combining different objectives, we set weighing factors to
the losses to $1$.

For comparison with the state-of-the-art [cite:@walsh22], we select the model so
as to maximize the area under the curve (ROC).

* Results


#+print_bibliography:
